{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUMO_GUI = True # set to True to use sumo-gui\n",
    "TOTAL_TIME = 1800 # 60 * 30 = 30 min\n",
    "NUM_SEEDS = 5\n",
    "NUM_EPISODES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from traffic_tail.environment import create_env\n",
    "from traffic_tail.trainer import SUMOTrainer\n",
    "\n",
    "\n",
    "def run_episode(env, agent):\n",
    "    total_reward = 0\n",
    "    state = env.reset()\n",
    "    done = {\"__all__\": False}\n",
    "    while not done[\"__all__\"]:\n",
    "        actions = {\n",
    "            ts_id: agent[ts_id].act(state[ts_id]) \n",
    "            for ts_id in state.keys()\n",
    "        }\n",
    "        state, reward, done, _ = env.step(actions)\n",
    "        total_reward += sum(reward.values())\n",
    "    env.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_curve_default = []\n",
    "for _ in range(NUM_SEEDS):\n",
    "    trainer_default = SUMOTrainer(\n",
    "        env='default', \n",
    "        use_gui=USE_SUMO_GUI,\n",
    "        num_seconds=TOTAL_TIME,\n",
    "    )\n",
    "    trainer_default.train(episodes=NUM_EPISODES)\n",
    "    reward_curve_default.append(trainer_default.rewards)\n",
    "\n",
    "data = []\n",
    "for i, reward_curve in enumerate(reward_curve_default):\n",
    "    for j, reward in enumerate(reward_curve):\n",
    "        data.append({\n",
    "            'step': j,\n",
    "            'reward': reward,\n",
    "            'run': i,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "sns.set()\n",
    "sns.lineplot(x='step', y='reward', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_curve_tailgating = []\n",
    "for _ in range(NUM_SEEDS):\n",
    "    trainer_tailgating = SUMOTrainer(\n",
    "        env='tailgating', \n",
    "        use_gui=USE_SUMO_GUI,\n",
    "        num_seconds=TOTAL_TIME,\n",
    "    )\n",
    "    trainer_tailgating.load('results/default/best_agents.pkl')\n",
    "    trainer_tailgating.train(episodes=NUM_EPISODES) \n",
    "    reward_curve_tailgating.append(trainer_default.rewards)\n",
    "\n",
    "data = []\n",
    "for i, reward_curve in enumerate(reward_curve_tailgating):\n",
    "    for j, reward in enumerate(reward_curve):\n",
    "        data.append({\n",
    "            'step': j,\n",
    "            'reward': reward,\n",
    "            'run': i,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "sns.set()\n",
    "sns.lineplot(x='step', y='reward', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_curve_overspeeding = []\n",
    "for _ in range(NUM_SEEDS):\n",
    "    trainer_tailgating = SUMOTrainer(\n",
    "        env='overspeeding', \n",
    "        use_gui=USE_SUMO_GUI,\n",
    "        num_seconds=TOTAL_TIME,\n",
    "    )\n",
    "    trainer_tailgating.load('results/default/best_agents.pkl')\n",
    "    trainer_tailgating.train(episodes=NUM_EPISODES) \n",
    "    reward_curve_overspeeding.append(trainer_default.rewards)\n",
    "\n",
    "data = []\n",
    "for i, reward_curve in enumerate(reward_curve_overspeeding):\n",
    "    for j, reward in enumerate(reward_curve):\n",
    "        data.append({\n",
    "            'step': j,\n",
    "            'reward': reward,\n",
    "            'run': i,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "sns.set()\n",
    "sns.lineplot(x='step', y='reward', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom environment with tailgating behavior.\n",
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 12ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      "Using custom environment with tailgating behavior.\n",
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 15ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      "Using default SUMO environment.\n",
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 16ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      "Initializing RL agents. (This may take a while)\n",
      "Using custom environment with tailgating behavior.\n",
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 15ms, vehicles TOT 0 ACT 0 BUF 0)                     \n",
      "Initializing RL agents. (This may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      " Retrying in 1 seconds\n",
      " Retrying in 1 seconds\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:10<19:37, 130.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:41<24:15, 161.71s/it]\n"
     ]
    },
    {
     "ename": "FatalTraCIError",
     "evalue": "Connection closed by SUMO.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalTraCIError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m ttr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)):\n\u001b[0;32m---> 24\u001b[0m     ddr\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_agent\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m     ttr\u001b[38;5;241m.\u001b[39mappend(run_episode(tailgating_env, tailgating_agent))\n\u001b[1;32m     26\u001b[0m     tdr\u001b[38;5;241m.\u001b[39mappend(run_episode(tailgating_env, default_agent))\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mrun_episode\u001b[0;34m(env, agent)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__all__\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     actions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m         ts_id: agent[ts_id]\u001b[38;5;241m.\u001b[39mact(state[ts_id]) \n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ts_id \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     19\u001b[0m     }\n\u001b[0;32m---> 20\u001b[0m     state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(reward\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     22\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/sumo_rl/environment/env.py:313\u001b[0m, in \u001b[0;36mSumoEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_actions(action)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_observations()\n\u001b[1;32m    316\u001b[0m rewards \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_rewards()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/sumo_rl/environment/env.py:330\u001b[0m, in \u001b[0;36mSumoEnvironment._run_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m time_to_act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_to_act:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sumo_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mts_ids:\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraffic_signals[ts]\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/local/traffic-tail/traffic_tail/environment.py:56\u001b[0m, in \u001b[0;36mTailGatingEnv._sumo_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tailgating()\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_realistic_impatience_gap()\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msumo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulationStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/traci/main.py:198\u001b[0m, in \u001b[0;36msimulationStep\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulationStep\u001b[39m(step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"simulationStep(float) -> None\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Make a simulation step and simulate up to the given second in sim time.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    If the given value is 0 or absent, exactly one step is performed.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m    Values smaller than or equal to the current sim time result in no action.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulationStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/traci/connection.py:368\u001b[0m, in \u001b[0;36mConnection.simulationStep\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(step) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[1;32m    367\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI change now handles step as floating point seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 368\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendCmd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCMD_SIMSTEP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subscriptionResults \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subscriptionMapping\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    370\u001b[0m     subscriptionResults\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/traci/connection.py:231\u001b[0m, in \u001b[0;36mConnection._sendCmd\u001b[0;34m(self, cmdID, varID, objID, format, *values)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(objID)) \u001b[38;5;241m+\u001b[39m objID\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_string \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m packed\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendExact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/sumo/lib/python3.9/site-packages/traci/connection.py:137\u001b[0m, in \u001b[0;36mConnection._sendExact\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FatalTraCIError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection closed by SUMO.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m command \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue:\n\u001b[1;32m    139\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!BBB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFatalTraCIError\u001b[0m: Connection closed by SUMO."
     ]
    }
   ],
   "source": [
    "default_env = create_env(tailgating=False, use_gui=USE_SUMO_GUI, num_seconds=TOTAL_TIME)\n",
    "tailgating_env = create_env(tailgating=True, use_gui=USE_SUMO_GUI, num_seconds=TOTAL_TIME)\n",
    "overspeeding_env = create_env(tailgating=False, use_gui=USE_SUMO_GUI, num_seconds=TOTAL_TIME, default_mode=24)\n",
    "\n",
    "trainer_default = SUMOTrainer(\n",
    "    env='default', \n",
    "    use_gui=USE_SUMO_GUI,\n",
    "    num_seconds=TOTAL_TIME,\n",
    ").load('results/default/best_agents.pkl')\n",
    "trainer_tailgating = SUMOTrainer(\n",
    "    env='tailgating', \n",
    "    use_gui=USE_SUMO_GUI,\n",
    "    num_seconds=TOTAL_TIME,\n",
    ").load('results/tailgating/best_agents.pkl')\n",
    "trainer_overspeeding = SUMOTrainer(\n",
    "    env='overspeeding', \n",
    "    use_gui=USE_SUMO_GUI,\n",
    "    num_seconds=TOTAL_TIME,\n",
    ").load('results/tailgating/best_agents.pkl')\n",
    "\n",
    "default_agent = trainer_default.agents\n",
    "tailgating_agent = trainer_tailgating.agents\n",
    "overspeeding_agent = trainer_overspeeding.agents\n",
    "\n",
    "ddr = []\n",
    "dtr = []\n",
    "tdr = []\n",
    "ttr = []\n",
    "oor = []\n",
    "odr = []\n",
    "dor = []\n",
    "\n",
    "for _ in tqdm(range(NUM_SEEDS)):\n",
    "    ddr.append(run_episode(default_env, default_agent))\n",
    "    ttr.append(run_episode(tailgating_env, tailgating_agent))\n",
    "    tdr.append(run_episode(tailgating_env, default_agent))\n",
    "    dtr.append(run_episode(default_env, tailgating_agent))\n",
    "    oor.append(run_episode(overspeeding_env, overspeeding_agent))\n",
    "    odr.append(run_episode(overspeeding_env, default_agent))\n",
    "    dor.append(run_episode(default_env, overspeeding_agent))\n",
    "\n",
    "print(f\"Default Agent in Default Environment: {sum(ddr)/len(ddr)}\")\n",
    "print(f\"Tailgating Agent in Tailgating Environment: {sum(ttr)/len(ttr)}\")\n",
    "print(f\"Default Agent in Tailgating Environment: {sum(tdr)/len(tdr)}\")\n",
    "print(f\"Tailgating Agent in Default Environment: {sum(dtr)/len(dtr)}\")\n",
    "print(f\"Overspeeding Agent in Overspeeding Environment: {sum(oor)/len(oor)}\")\n",
    "print(f\"Overspeeding Agent in Default Environment: {sum(dor)/len(dor)}\")\n",
    "print(f\"Default Agent in Overspeeding Environment: {sum(odr)/len(odr)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
